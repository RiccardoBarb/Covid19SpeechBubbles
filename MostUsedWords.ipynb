{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import glob\n",
    "import os\n",
    "from gensim.utils import lemmatize\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = []\n",
    "for root, dirs, files in os.walk('txt/'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "             filelist.append((os.path.join(root, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['usa',\n",
       " 'irleand',\n",
       " 'norway',\n",
       " 'france',\n",
       " 'korea',\n",
       " 'spain',\n",
       " 'australia',\n",
       " 'germany',\n",
       " 'argentina',\n",
       " 'portugal',\n",
       " 'switzerland',\n",
       " 'japan',\n",
       " 'colombia',\n",
       " 'china',\n",
       " 'uk',\n",
       " 'southafrica',\n",
       " 'hungary',\n",
       " 'singapore',\n",
       " 'who',\n",
       " 'romania',\n",
       " 'italy',\n",
       " 'denmark',\n",
       " 'philippines',\n",
       " 'netherland',\n",
       " 'peru',\n",
       " 'iran',\n",
       " 'chzech',\n",
       " 'vietnam',\n",
       " 'greece',\n",
       " 'chile']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [i.split('/')[1] for i in filelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patt = re.compile('covid|coronavirus|covid-19')\n",
    "documents=[]\n",
    "\n",
    "for i in filelist:\n",
    "    current = open(i).read()\n",
    "    #we preprocess the text files to remove spaces and new lines\n",
    "    txa = unicodedata.normalize('NFKD',current)\n",
    "    txa = txa.replace(u'\\n', u' ')\n",
    "    txa = re.sub(patt,'virus',txa.lower())\n",
    "    documents.append(txa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_used_adjective = []\n",
    "most_used_noun = []\n",
    "adj_count = []\n",
    "nou_count = []\n",
    "\n",
    "for i in range(len(documents)):\n",
    "    \n",
    "    adj = [wd.decode('utf-8').split('/')[0] \n",
    "           for wd in lemmatize(documents[i])\n",
    "           if wd.decode('utf-8').split('/')[-1]=='JJ'\n",
    "           and wd.decode('utf-8').split('/')[0]!='such'\n",
    "           and wd.decode('utf-8').split('/')[0]!='more'] \n",
    "    \n",
    "    noun = [wd.decode('utf-8').split('/')[0] \n",
    "           for wd in lemmatize(documents[i])\n",
    "            if wd.decode('utf-8').split('/')[-1]=='NN'] \n",
    "    \n",
    "    adj_u,adj_c = np.unique(np.asarray(adj),return_counts=1)\n",
    "    id_a = np.argmax(adj_c)\n",
    "    m_ada = adj_u[id_a]\n",
    "    most_used_adjective.append(m_ada)\n",
    "    adj_count.append(np.max(adj_c))\n",
    "    \n",
    "    nou_u,nou_c = np.unique(np.asarray(noun),return_counts=1)\n",
    "    id_n = np.argmax(nou_c)\n",
    "    n_ada = nou_u[id_n]\n",
    "    most_used_noun.append(n_ada)\n",
    "    nou_count.append(np.max(nou_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 'economic', 'usa')\n",
      "(3, 'important', 'irleand')\n",
      "(7, 'other', 'norway')\n",
      "(11, 'european', 'france')\n",
      "(14, 'local', 'korea')\n",
      "(16, 'economic', 'spain')\n",
      "(3, 'good', 'australia')\n",
      "(6, 'federal', 'germany')\n",
      "(3, 'important', 'argentina')\n",
      "(5, 'new', 'portugal')\n",
      "(6, 'federal', 'switzerland')\n",
      "(10, 'possible', 'japan')\n",
      "(5, 'young', 'colombia')\n",
      "(32, 'necessary', 'china')\n",
      "(6, 'few', 'uk')\n",
      "(8, 'national', 'southafrica')\n",
      "(6, 'public', 'hungary')\n",
      "(12, 'new', 'singapore')\n",
      "(3, 'other', 'who')\n",
      "(8, 'economic', 'romania')\n",
      "(6, 'great', 'italy')\n",
      "(8, 'new', 'denmark')\n",
      "(10, 'military', 'philippines')\n",
      "(4, 'important', 'netherland')\n",
      "(5, 'difficult', 'peru')\n",
      "(6, 'other', 'iran')\n",
      "(9, 'czech', 'chzech')\n",
      "(8, 'prime', 'vietnam')\n",
      "(6, 'public', 'greece')\n",
      "(9, 'necessary', 'chile')\n"
     ]
    }
   ],
   "source": [
    "for ad in zip(adj_count,most_used_adjective,labels):\n",
    "    print(ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 'virus', 'usa')\n",
      "(9, 'person', 'irleand')\n",
      "(12, 'measure', 'norway')\n",
      "(17, 'virus', 'france')\n",
      "(19, 'government', 'korea')\n",
      "(28, 'health', 'spain')\n",
      "(10, 'virus', 'australia')\n",
      "(12, 'facility', 'germany')\n",
      "(10, 'person', 'argentina')\n",
      "(14, 'health', 'portugal')\n",
      "(15, 'switzerland', 'switzerland')\n",
      "(18, 'screening', 'japan')\n",
      "(7, 'team', 'colombia')\n",
      "(76, 'epidemic', 'china')\n",
      "(10, 'disease', 'uk')\n",
      "(23, 'country', 'southafrica')\n",
      "(11, 'person', 'hungary')\n",
      "(12, 'virus', 'singapore')\n",
      "(21, 'country', 'who')\n",
      "(17, 'virus', 'romania')\n",
      "(8, 'health', 'italy')\n",
      "(13, 'authority', 'denmark')\n",
      "(20, 'department', 'philippines')\n",
      "(20, 'person', 'netherland')\n",
      "(11, 'measure', 'peru')\n",
      "(17, 'country', 'iran')\n",
      "(19, 'government', 'chzech')\n",
      "(38, 'epidemic', 'vietnam')\n",
      "(6, 'citizen', 'greece')\n",
      "(23, 'health', 'chile')\n"
     ]
    }
   ],
   "source": [
    "for ad in zip(nou_count,most_used_noun,labels):\n",
    "    print(ad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
